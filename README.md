# Machine Learning Course: Mini Projects

Welcome to the repository for the Machine Learning course mini projects. This repository contains the implementation, analysis, and evaluation of various machine learning algorithms and techniques through four mini projects. Each mini project explores different aspects of machine learning, from classification and regression to neural networks and reinforcement learning. Please contact the teaching assistant, Mr. Javad Ahmadi, at [ai.kntu.ac@gmail.com](mailto:ai.kntu.ac@gmail.com)

## Course Overview

This Machine Learning course is offered by the Mechatronics/Control group at K. N. Toosi University of Technology. The course covers a broad range of topics in machine learning, providing both theoretical foundations and practical applications. The main areas of focus include supervised and unsupervised learning, neural networks, and reinforcement learning. The course aims to develop skills for implementing and evaluating machine learning models using tools like Python and MATLAB.

### Instructor and TA Information
- **Instructor:** Dr. Mehdi Aliyari
  - Email: [aliyari@kntu.ac.ir](mailto:aliyari@kntu.ac.ir)
- **Teaching Assistant:** Mr. Javad Ahmadi
  - Email: [ai.kntu.ac@gmail.com](mailto:ai.kntu.ac@gmail.com)

### References
- Tom Mitchell, “Machine Learning”, McGraw Hill, 1997.
- Christopher M. Bishop, “Pattern Recognition and Machine Learning”, Springer, 2006.
- S. Theodoridis and K. Koutroumbas, "Pattern Recognition", Fourth Edition, Academic Press, 2009.
- K. Murphy, “Machine Learning: A Probabilistic Perspective”, MIT Press, 2012.
- Martin T Hagan et al., “Neural Network Design”, 2nd Edition, 2014.
- Li-Xin Wang, “A Course in Fuzzy Systems and Control”, Prentice Hall, 1996.

### Course Topics
1. **Introduction to Machine Learning and Classifiers:** Overview of machine learning, types of learning, classifiers, and clustering methods.
2. **Regression:** Least squares, gradient descent, logistic regression, and regularized least squares.
3. **Linear Classifiers and Bayesian Decision Theory:** Linear classifiers, multi-class classifiers, Bayesian decision theory, and non-parametric methods.
4. **Dimensionality Reduction:** PCA, LDA, and non-linear dimensionality reduction techniques.
5. **Support Vector Machines (SVM):** Linear and kernel-based SVMs.
6. **Neural Networks:** Basics of neural networks, MLP, activation functions, backpropagation, and applications.
7. **Instance-Based Learning and Fuzzy Systems:** KNN, RBF networks, fuzzy logic, and fuzzy inference systems.
8. **Decision Trees and Ensemble Methods:** Decision tree algorithms, bagging, boosting, and AdaBoost.
9. **Reinforcement Learning:** Q-learning, deep Q-networks, and applications in game playing.
10. **Evolutionary Algorithms:** Genetic algorithms and gradient-based optimization methods.

## Mini Projects

### Mini Project 1: Training and Evaluating Machine Learning Classifiers
- **Objective:** To train and evaluate various classifiers and regression models using synthetic and real-world datasets.
- **Concepts Covered:**
  - **Linear Classifier:** Training and evaluation of linear classifiers on synthetic datasets.
  - **Multi-layer Perceptron (MLP):** Feature extraction and model training using MLP on the CWRU Bearing dataset.
  - **Regression Analysis:** Applying Least Squares (LS), Regularized Least Squares (RLS), and Weighted Least Squares (WLS) techniques for regression tasks.

### Mini Project 2: Comparative Analysis of Machine Learning Classifiers
- **Objective:** To compare the performance of various machine learning classifiers on different datasets.
- **Concepts Covered:**
  - **Multi-layer Perceptron (MLP):** Implementation and evaluation of MLP with different architectures and activation functions.
  - **Random Forest and Ensemble Methods:** Training and evaluating Random Forest classifiers and comparing with other ensemble methods like AdaBoost.
  - **Naive Bayes:** Application of Naive Bayes classifiers for probabilistic classification tasks.

### Mini Project 3: Support Vector Machines (SVM) and Dimensionality Reduction
- **Objective:** To analyze the impact of various dimensionality reduction techniques on the performance of Support Vector Machines (SVM).
- **Concepts Covered:**
  - **Dimensionality Reduction:** Implementation and comparison of techniques like t-SNE, PCA, and LDA.
  - **Support Vector Machines (SVM):** Evaluation of SVM with linear and polynomial kernels, including custom implementations.
  - **Data Preprocessing:** Techniques like autoencoders for data denoising and SMOTE for addressing class imbalance.

### Mini Project 4: Reinforcement Learning Algorithms
- **Objective:** To explore and implement reinforcement learning algorithms to solve the Wumpus World problem.
- **Concepts Covered:**
  - **Q-learning:** Implementation of Q-learning for training agents in a grid-based environment.
  - **Deep Q-Networks (DQN):** Using neural networks to approximate Q-values, with techniques like experience replay and target networks to stabilize training.
  - **Performance Evaluation:** Training agents and evaluating their performance based on various reward metrics.

## Contact

For any questions or issues, please contact Me at [masihmj00@gmail.com](mailto:masihmj00@gmail.com) 
